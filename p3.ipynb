{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b1b726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Prob: \n",
      "[0.1642, 0.067, 0.0158, 0.0233, 0.0305, 0.0907, 0.0166, 0.0222, 0.0449, 0.0509, 0.0024, 0.0125, 0.037, 0.0222, 0.0598, 0.0713, 0.0163, 0.0003, 0.0471, 0.0566, 0.0713, 0.0286, 0.0069, 0.0181, 0.0028, 0.0191, 0.0016]\n",
      "\n",
      "\n",
      "Bigram prob without Laplace Smoothing: \n",
      "0.0,0.0903,0.0593,0.0548,0.0453,0.0148,0.0366,0.0347,0.0595,0.0532,0.0119,0.0099,0.0366,0.0417,0.0181,0.0549,0.0311,0.0007,0.0272,0.0732,0.1488,0.0138,0.0059,0.0523,0.0,0.0252,0.0001,\n",
      "\n",
      "0.088,0.0003,0.0167,0.0538,0.0322,0.0003,0.0058,0.023,0.0017,0.0259,0.0012,0.0213,0.082,0.0411,0.1769,0.0003,0.025,0.0,0.1059,0.059,0.1174,0.0319,0.015,0.0092,0.0,0.0647,0.0014,\n",
      "\n",
      "0.0196,0.3032,0.0257,0.0,0.0012,0.1149,0.0012,0.0012,0.0,0.0416,0.0012,0.0,0.0868,0.0024,0.0,0.1797,0.0,0.0,0.0391,0.0183,0.0,0.11,0.0037,0.0,0.0,0.0501,0.0,\n",
      "\n",
      "0.0157,0.1258,0.0,0.0083,0.0,0.1283,0.0,0.0,0.2111,0.043,0.0,0.0969,0.0439,0.0008,0.0,0.1639,0.0,0.0,0.0712,0.0,0.0397,0.0439,0.0,0.0008,0.0,0.0066,0.0,\n",
      "\n",
      "0.3548,0.0619,0.0044,0.0013,0.0088,0.1679,0.0019,0.0107,0.0013,0.0732,0.0019,0.0006,0.0114,0.0019,0.0069,0.1566,0.0006,0.0,0.0259,0.0682,0.0044,0.0057,0.0006,0.0025,0.0,0.0265,0.0,\n",
      "\n",
      "0.3424,0.0567,0.0049,0.0246,0.0529,0.0261,0.0047,0.0034,0.004,0.0121,0.0004,0.0017,0.0446,0.0153,0.0932,0.0064,0.0083,0.0006,0.1111,0.0886,0.0331,0.0036,0.0142,0.0098,0.0151,0.0176,0.0045,\n",
      "\n",
      "0.2561,0.0582,0.0035,0.0,0.0012,0.0466,0.0861,0.0012,0.0,0.0978,0.0,0.0,0.0419,0.0012,0.0,0.1839,0.0012,0.0,0.1467,0.0058,0.0338,0.0244,0.0,0.007,0.0,0.0035,0.0,\n",
      "\n",
      "0.2769,0.0677,0.0043,0.0009,0.0009,0.1285,0.0043,0.0095,0.1068,0.0286,0.0,0.0009,0.0295,0.0,0.0122,0.1424,0.0017,0.0,0.0712,0.053,0.0017,0.0573,0.0,0.0009,0.0,0.0009,0.0,\n",
      "\n",
      "0.06,0.1312,0.0017,0.0004,0.0,0.4974,0.0,0.0013,0.0,0.1321,0.0,0.0,0.0026,0.0,0.0004,0.0909,0.0,0.0,0.0189,0.003,0.0395,0.0146,0.0,0.0004,0.0,0.0056,0.0,\n",
      "\n",
      "0.0477,0.0133,0.0045,0.0485,0.0269,0.025,0.0201,0.0462,0.0072,0.0008,0.0,0.0136,0.0598,0.0511,0.3102,0.0311,0.0072,0.0004,0.0367,0.1121,0.1057,0.003,0.0227,0.0004,0.0008,0.0008,0.0042,\n",
      "\n",
      "0.0,0.0569,0.0,0.0,0.0,0.0488,0.0,0.0,0.0,0.0081,0.0,0.0,0.0,0.0,0.0,0.6423,0.0,0.0,0.0,0.0,0.0,0.2439,0.0,0.0,0.0,0.0,0.0,\n",
      "\n",
      "0.2473,0.0031,0.0015,0.0,0.0077,0.3134,0.0031,0.0015,0.0046,0.0937,0.0015,0.0,0.0123,0.0046,0.0722,0.0276,0.0015,0.0,0.0,0.169,0.0031,0.0015,0.0,0.0123,0.0,0.0184,0.0,\n",
      "\n",
      "0.1443,0.1131,0.001,0.0026,0.0505,0.1443,0.0323,0.0021,0.0016,0.112,0.001,0.0115,0.1376,0.0047,0.0026,0.1094,0.0057,0.0,0.0026,0.0516,0.0151,0.0125,0.0036,0.0047,0.0,0.0334,0.0,\n",
      "\n",
      "0.1709,0.2402,0.0434,0.0087,0.0043,0.1622,0.0026,0.0026,0.0009,0.0841,0.0,0.0,0.0009,0.0113,0.0026,0.1006,0.0642,0.0,0.0217,0.026,0.0035,0.0199,0.0009,0.0009,0.0,0.0278,0.0,\n",
      "\n",
      "0.2026,0.0306,0.0032,0.0206,0.1043,0.1101,0.0039,0.1324,0.0023,0.0396,0.0006,0.029,0.0064,0.0042,0.0087,0.0467,0.0006,0.0,0.0016,0.0467,0.1771,0.0103,0.0045,0.0048,0.0,0.009,0.0,\n",
      "\n",
      "0.1066,0.0068,0.0143,0.0078,0.02,0.0065,0.0636,0.0076,0.0008,0.0111,0.0003,0.0403,0.0373,0.0398,0.1461,0.0555,0.0311,0.0,0.0825,0.0214,0.0403,0.1496,0.0151,0.0671,0.0197,0.0024,0.0065,\n",
      "\n",
      "0.1427,0.0637,0.0012,0.0012,0.0012,0.1568,0.0,0.0035,0.0342,0.0637,0.0,0.0,0.0873,0.0012,0.0012,0.0767,0.0566,0.0,0.0708,0.092,0.0106,0.0672,0.0,0.0024,0.0,0.066,0.0,\n",
      "\n",
      "0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,\n",
      "\n",
      "0.169,0.0884,0.0049,0.0057,0.0675,0.205,0.0049,0.0131,0.0033,0.0876,0.0008,0.0135,0.0082,0.0119,0.0229,0.1146,0.0078,0.0,0.0213,0.0511,0.0217,0.0368,0.0082,0.0086,0.0,0.0233,0.0,\n",
      "\n",
      "0.4884,0.0174,0.0031,0.029,0.0058,0.0654,0.0031,0.0054,0.0446,0.0559,0.0007,0.0116,0.0126,0.015,0.0051,0.0296,0.0174,0.001,0.0037,0.0371,0.1104,0.0242,0.0007,0.0099,0.0,0.0027,0.0,\n",
      "\n",
      "0.2305,0.0427,0.0027,0.0073,0.0062,0.063,0.0027,0.0062,0.2961,0.053,0.0,0.0,0.0116,0.0281,0.0011,0.1086,0.0005,0.0,0.0295,0.0535,0.0138,0.0154,0.0022,0.0111,0.0,0.0132,0.0011,\n",
      "\n",
      "0.1171,0.0262,0.0135,0.0323,0.0141,0.0141,0.0054,0.0363,0.0013,0.0242,0.0007,0.0,0.07,0.0505,0.1077,0.0182,0.0639,0.0,0.1447,0.1137,0.1164,0.0,0.0087,0.004,0.0,0.0135,0.0034,\n",
      "\n",
      "0.0306,0.1278,0.0,0.0028,0.0,0.6556,0.0,0.0028,0.0,0.125,0.0,0.0,0.0028,0.0,0.0,0.0278,0.0167,0.0,0.0,0.0028,0.0,0.0028,0.0,0.0,0.0,0.0028,0.0,\n",
      "\n",
      "0.1035,0.2764,0.0021,0.0011,0.0075,0.1419,0.0043,0.0,0.1163,0.1291,0.0,0.0011,0.0075,0.0011,0.0907,0.0576,0.0,0.0,0.0117,0.0331,0.0011,0.0064,0.0,0.0032,0.0,0.0043,0.0,\n",
      "\n",
      "0.2945,0.0411,0.0068,0.0342,0.0068,0.0137,0.0068,0.0,0.0068,0.0685,0.0,0.0,0.0,0.0,0.0068,0.0068,0.0616,0.0,0.0068,0.0205,0.3288,0.0,0.0,0.0411,0.0,0.0479,0.0,\n",
      "\n",
      "0.3862,0.0162,0.0091,0.0061,0.0091,0.0303,0.0111,0.0283,0.0061,0.0303,0.001,0.001,0.0152,0.002,0.1092,0.2679,0.001,0.0,0.0131,0.0212,0.0162,0.0,0.0061,0.0101,0.0,0.003,0.0,\n",
      "\n",
      "0.1728,0.0494,0.0,0.0,0.0,0.0988,0.0,0.0123,0.0247,0.037,0.0,0.0,0.0494,0.0,0.0,0.3086,0.0,0.0,0.0123,0.0,0.0247,0.0123,0.0,0.0,0.0,0.0741,0.1235,\n",
      "\n",
      "Bigram prob with Laplace Smoothing: \n",
      "0.0001,0.0901,0.0592,0.0548,0.0453,0.0149,0.0366,0.0347,0.0594,0.0531,0.0119,0.0099,0.0366,0.0417,0.0181,0.0549,0.0311,0.0008,0.0273,0.0731,0.1485,0.0139,0.006,0.0523,0.0001,0.0253,0.0002,\n",
      "\n",
      "0.0876,0.0006,0.0168,0.0537,0.0323,0.0006,0.006,0.0231,0.002,0.026,0.0014,0.0214,0.0816,0.0411,0.1758,0.0006,0.0251,0.0003,0.1053,0.0588,0.1168,0.032,0.0151,0.0094,0.0003,0.0645,0.0017,\n",
      "\n",
      "0.0201,0.2947,0.026,0.0012,0.0024,0.1124,0.0024,0.0024,0.0012,0.0414,0.0024,0.0012,0.0852,0.0036,0.0012,0.1751,0.0012,0.0012,0.0391,0.0189,0.0012,0.1077,0.0047,0.0012,0.0012,0.0497,0.0012,\n",
      "\n",
      "0.0162,0.1239,0.0008,0.0089,0.0008,0.1263,0.0008,0.0008,0.2073,0.0429,0.0008,0.0955,0.0437,0.0016,0.0008,0.1611,0.0008,0.0008,0.0704,0.0008,0.0397,0.0437,0.0008,0.0016,0.0008,0.0073,0.0008,\n",
      "\n",
      "0.3495,0.0615,0.005,0.0019,0.0093,0.1657,0.0025,0.0112,0.0019,0.0726,0.0025,0.0012,0.0118,0.0025,0.0074,0.1546,0.0012,0.0006,0.0261,0.0677,0.005,0.0062,0.0012,0.0031,0.0006,0.0267,0.0006,\n",
      "\n",
      "0.3407,0.0566,0.0051,0.0247,0.0528,0.0262,0.0049,0.0036,0.0042,0.0122,0.0006,0.0019,0.0446,0.0154,0.0929,0.0065,0.0084,0.0008,0.1107,0.0883,0.0332,0.0038,0.0144,0.0099,0.0152,0.0177,0.0046,\n",
      "\n",
      "0.2494,0.0576,0.0045,0.0011,0.0023,0.0463,0.0847,0.0023,0.0011,0.0959,0.0011,0.0011,0.0418,0.0023,0.0011,0.1795,0.0023,0.0011,0.1433,0.0068,0.0339,0.0248,0.0011,0.0079,0.0011,0.0045,0.0011,\n",
      "\n",
      "0.2714,0.067,0.0051,0.0017,0.0017,0.1264,0.0051,0.0102,0.1052,0.0288,0.0008,0.0017,0.0297,0.0008,0.0127,0.1399,0.0025,0.0008,0.0704,0.0526,0.0025,0.0568,0.0008,0.0017,0.0008,0.0017,0.0008,\n",
      "\n",
      "0.0598,0.1301,0.0021,0.0008,0.0004,0.4922,0.0004,0.0017,0.0004,0.131,0.0004,0.0004,0.003,0.0004,0.0008,0.0903,0.0004,0.0004,0.0191,0.0034,0.0394,0.0148,0.0004,0.0008,0.0004,0.0059,0.0004,\n",
      "\n",
      "0.0476,0.0135,0.0049,0.0484,0.027,0.0251,0.0202,0.0461,0.0075,0.0011,0.0004,0.0139,0.0596,0.051,0.3075,0.0311,0.0075,0.0007,0.0367,0.1114,0.105,0.0034,0.0229,0.0007,0.0011,0.0011,0.0045,\n",
      "\n",
      "0.0067,0.0533,0.0067,0.0067,0.0067,0.0467,0.0067,0.0067,0.0067,0.0133,0.0067,0.0067,0.0067,0.0067,0.0067,0.5333,0.0067,0.0067,0.0067,0.0067,0.0067,0.2067,0.0067,0.0067,0.0067,0.0067,0.0067,\n",
      "\n",
      "0.2389,0.0044,0.0029,0.0015,0.0088,0.3024,0.0044,0.0029,0.0059,0.0914,0.0029,0.0015,0.0133,0.0059,0.0708,0.028,0.0029,0.0015,0.0015,0.1637,0.0044,0.0029,0.0015,0.0133,0.0015,0.0192,0.0015,\n",
      "\n",
      "0.1429,0.112,0.0015,0.0031,0.0504,0.1429,0.0324,0.0026,0.0021,0.111,0.0015,0.0118,0.1362,0.0051,0.0031,0.1084,0.0062,0.0005,0.0031,0.0514,0.0154,0.0128,0.0041,0.0051,0.0005,0.0334,0.0005,\n",
      "\n",
      "0.1678,0.2356,0.0432,0.0093,0.0051,0.1593,0.0034,0.0034,0.0017,0.0831,0.0008,0.0008,0.0017,0.0119,0.0034,0.0992,0.0636,0.0008,0.022,0.0263,0.0042,0.0203,0.0017,0.0017,0.0008,0.028,0.0008,\n",
      "\n",
      "0.2011,0.0307,0.0035,0.0208,0.1038,0.1095,0.0042,0.1315,0.0026,0.0396,0.001,0.0291,0.0067,0.0045,0.0089,0.0466,0.001,0.0003,0.0019,0.0466,0.1759,0.0105,0.0048,0.0051,0.0003,0.0093,0.0003,\n",
      "\n",
      "0.1061,0.007,0.0145,0.0081,0.0201,0.0067,0.0634,0.0078,0.0011,0.0113,0.0005,0.0403,0.0373,0.0397,0.1453,0.0553,0.0311,0.0003,0.0822,0.0215,0.0403,0.1488,0.0153,0.0669,0.0199,0.0027,0.0067,\n",
      "\n",
      "0.1394,0.0629,0.0023,0.0023,0.0023,0.1531,0.0011,0.0046,0.0343,0.0629,0.0011,0.0011,0.0857,0.0023,0.0023,0.0754,0.056,0.0011,0.0697,0.0903,0.0114,0.0663,0.0011,0.0034,0.0011,0.0651,0.0011,\n",
      "\n",
      "0.025,0.025,0.025,0.025,0.025,0.025,0.025,0.025,0.025,0.025,0.025,0.025,0.025,0.025,0.025,0.025,0.025,0.025,0.025,0.025,0.025,0.35,0.025,0.025,0.025,0.025,0.025,\n",
      "\n",
      "0.1675,0.0878,0.0053,0.0061,0.0672,0.2032,0.0053,0.0134,0.0036,0.087,0.0012,0.0138,0.0085,0.0121,0.0231,0.1137,0.0081,0.0004,0.0214,0.051,0.0219,0.0368,0.0085,0.0089,0.0004,0.0235,0.0004,\n",
      "\n",
      "0.4843,0.0175,0.0034,0.029,0.0061,0.0651,0.0034,0.0057,0.0445,0.0557,0.001,0.0118,0.0128,0.0152,0.0054,0.0297,0.0175,0.0013,0.004,0.0371,0.1097,0.0243,0.001,0.0101,0.0003,0.003,0.0003,\n",
      "\n",
      "0.2291,0.0427,0.003,0.0075,0.0064,0.0628,0.003,0.0064,0.2943,0.0528,0.0003,0.0003,0.0118,0.0282,0.0013,0.1081,0.0008,0.0003,0.0295,0.0534,0.0139,0.0156,0.0024,0.0113,0.0003,0.0134,0.0013,\n",
      "\n",
      "0.1157,0.0264,0.0139,0.0324,0.0145,0.0145,0.0059,0.0364,0.002,0.0245,0.0013,0.0007,0.0694,0.0502,0.1064,0.0185,0.0635,0.0007,0.1428,0.1124,0.115,0.0007,0.0093,0.0046,0.0007,0.0139,0.004,\n",
      "\n",
      "0.031,0.1214,0.0026,0.0052,0.0026,0.6124,0.0026,0.0052,0.0026,0.1189,0.0026,0.0026,0.0052,0.0026,0.0026,0.0284,0.0181,0.0026,0.0026,0.0052,0.0026,0.0052,0.0026,0.0026,0.0026,0.0052,0.0026,\n",
      "\n",
      "0.1017,0.2697,0.0031,0.0021,0.0083,0.139,0.0052,0.001,0.1141,0.1266,0.001,0.0021,0.0083,0.0021,0.0892,0.0571,0.001,0.001,0.0124,0.0332,0.0021,0.0073,0.001,0.0041,0.001,0.0052,0.001,\n",
      "\n",
      "0.2543,0.0405,0.0116,0.0347,0.0116,0.0173,0.0116,0.0058,0.0116,0.0636,0.0058,0.0058,0.0058,0.0058,0.0116,0.0116,0.0578,0.0058,0.0116,0.0231,0.2832,0.0058,0.0058,0.0405,0.0058,0.0462,0.0058,\n",
      "\n",
      "0.377,0.0167,0.0098,0.0069,0.0098,0.0305,0.0118,0.0285,0.0069,0.0305,0.002,0.002,0.0157,0.003,0.1073,0.2618,0.002,0.001,0.0138,0.0217,0.0167,0.001,0.0069,0.0108,0.001,0.0039,0.001,\n",
      "\n",
      "0.1389,0.0463,0.0093,0.0093,0.0093,0.0833,0.0093,0.0185,0.0278,0.037,0.0093,0.0093,0.0463,0.0093,0.0093,0.2407,0.0093,0.0093,0.0185,0.0093,0.0278,0.0185,0.0093,0.0093,0.0093,0.0648,0.1019,\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood probabilities of the Naive Bayes estimator for the fake script \n",
      "\n",
      "[0.094, 0.0021, 0.0143, 0.0107, 0.0052, 0.0024, 0.0082, 0.0101, 0.003, 0.002, 0.1311, 0.0179, 0.0045, 0.0092, 0.0031, 0.0025, 0.0109, 0.212, 0.0024, 0.0035, 0.002, 0.007, 0.0231, 0.0064, 0.1338, 0.0112, 0.2674]\n",
      "\n",
      "\n",
      "0.2516169172225196,0.018075232046897895,0.3470646113479829,0.21241549522480951,0.09101660438052889,0.01530269348084578,0.22487399940705605,0.21085594989561587,0.03775895499540769,0.02255616179473893,0.9697714868350027,0.4568216305697337,0.06666666666666667,0.19574468085106383,0.029545864351768373,0.02017712241514702,0.2819885330722976,0.9975963067061772,0.029056640816727198,0.03504451600681948,0.016207100462121378,0.12567934782608697,0.6628664495114006,0.17195555878294963,0.9655939145699239,0.25616616183470364,0.989914553859084,\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "## Written by: Wai Zin Linn\n",
    "## Attribution: Hugh Liu's solutions for CS540 2021 Epic and Hongtao Hao\n",
    "\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from itertools import permutations\n",
    "import random\n",
    "from numpy import cumsum\n",
    "import numpy as np\n",
    "\n",
    "# adjust on your own\n",
    "P_my = 0.63\n",
    "P_fake = 0.37\n",
    "num_charactors = 1000\n",
    "\n",
    "with open('darkknight.txt', encoding = 'utf-8') as f:\n",
    "    data = f.read()\n",
    "\n",
    "def process_text(data):\n",
    "    data = data.lower()\n",
    "    data = re.sub(r'[^a-z ]+', '', data)\n",
    "    data = ' '.join(data.split())\n",
    "    return data \n",
    "data = process_text(data)\n",
    "\n",
    "allchar = ' ' + string.ascii_lowercase\n",
    "unigram = Counter(data)\n",
    "unigram_prob = {ch: round(unigram[ch]/len(data),4) for ch in allchar}\n",
    "uni_list = [unigram_prob[c] for c in allchar]\n",
    "\n",
    "##q2\n",
    "print(\"Unigram Prob: \")\n",
    "print(uni_list)\n",
    "\n",
    "# to distinguish between fake_unigram_prob below\n",
    "my_unigram_prob = unigram_prob\n",
    "\n",
    "def ngram(n):\n",
    "    # all possible n-grams\n",
    "    d = dict.fromkeys([''.join(i) for i in product(allchar, repeat=n)],0)\n",
    "    # update counts\n",
    "    d.update(Counter(data[x:x+n] for x in range(len(data)-1)))\n",
    "    return d\n",
    "\n",
    "bigram = ngram(2)\n",
    "bigram_prob = {c: bigram[c] / unigram[c[0]] for c in bigram}\n",
    "bigram_lst = []\n",
    "big_lst = []\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "##q3\n",
    "count = 0;\n",
    "for c in bigram:\n",
    "    bigram_lst.append(round(bigram[c] / unigram[c[0]],4))\n",
    "    count += 1\n",
    "    if count%27 == 0:\n",
    "        big_lst.append(bigram_lst)\n",
    "        bigram_lst = []\n",
    "\n",
    "print(\"Bigram prob without Laplace Smoothing: \")\n",
    "counter = 0;\n",
    "for lst in big_lst:\n",
    "    for c in lst:\n",
    "        print(c,end=\",\")\n",
    "        counter += 1;\n",
    "        if counter%27 == 0:\n",
    "            print('\\n')\n",
    "    \n",
    "bigram_prob_L = {\n",
    "    c: (bigram[c] + 1) / (unigram[c[0]] + 27) for c in bigram}\n",
    "\n",
    "##q4\n",
    "\n",
    "print(\"Bigram prob with Laplace Smoothing: \")\n",
    "\n",
    "counter = 0\n",
    "for c in bigram:\n",
    "    print(round(bigram_prob_L[c],4),end=\",\")\n",
    "    counter += 1;\n",
    "    if counter%27 == 0:\n",
    "        print('\\n')\n",
    "\n",
    "trigram= ngram(3)\n",
    "trigram_prob_L = {c: (trigram[c] + 1) / (bigram[c[:2]] + 27) for c in trigram}\n",
    "\n",
    "# based on https://python-course.eu/numerical-programming/weighted-probabilities.php\n",
    "def weighted_choice(collection, weights):\n",
    "    weights = np.array(weights)\n",
    "    weights_sum = weights.sum()\n",
    "    weights = weights.cumsum()/weights_sum\n",
    "    x = random.random()\n",
    "    for i in range(len(weights)):\n",
    "        if x < weights[i]:\n",
    "            return collection[i]\n",
    "\n",
    "def gen_bi(c):\n",
    "    w = [bigram_prob[c+i] for i in allchar]\n",
    "    return weighted_choice(allchar, weights = w)[0]\n",
    "\n",
    "def gen_tri(ab):\n",
    "    w = [trigram_prob_L[ab+i] for i in allchar]\n",
    "    return weighted_choice(allchar, weights=w)[0]\n",
    "\n",
    "def gen_sen(c, num):\n",
    "    # generate the second char\n",
    "    res = c + gen_bi(c)\n",
    "    for i in range(num-2):\n",
    "        if bigram[res[-2:]] == 0:\n",
    "            t = gen_bi(res[-1])\n",
    "        else:\n",
    "            t = gen_tri(res[-2:])\n",
    "        res += t\n",
    "    return res\n",
    "\n",
    "\n",
    "sentences = []\n",
    "for char in allchar:\n",
    "    sentence = gen_sen(char, num_charactors)\n",
    "    sentences.append(sentence)\n",
    "    \n",
    "#q5\n",
    "\n",
    "with open('q5.txt', 'w') as f:\n",
    "    for sentence in sentences:\n",
    "        f.write(sentence)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "## fake script\n",
    "with open('script.txt', encoding = 'utf-8') as f:\n",
    "    data = f.read()\n",
    "\n",
    "data = process_text(data)\n",
    "\n",
    "unigram = Counter(data)\n",
    "unigram_prob = {ch: round(unigram[ch]/len(data),4) for ch in allchar}\n",
    "uni_list = [unigram_prob[c] for c in allchar]\n",
    "\n",
    "#q7\n",
    "print(\"Likelihood probabilities of the Naive Bayes estimator for the fake script\",\"\\n\")\n",
    "print(uni_list)\n",
    "print('\\n')\n",
    "\n",
    "fake_unigram_prob = unigram_prob\n",
    "\n",
    "#q8\n",
    "count = 0\n",
    "for char in allchar:\n",
    "    count += 1\n",
    "    print(P_fake*fake_unigram_prob[char]/(P_fake*fake_unigram_prob[char] + P_my*my_unigram_prob[char]),end=\",\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "#q9\n",
    "lst = []\n",
    "for sentence in sentences:\n",
    "    my = 0\n",
    "    fake = 0\n",
    "    for char in sentence:\n",
    "        my += np.log10(my_unigram_prob[char])\n",
    "        fake += np.log10(fake_unigram_prob[char])\n",
    "    if my > fake:\n",
    "        lst.append(int('0'))\n",
    "    else:\n",
    "        lst.append(int('1'))\n",
    "\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b936fd58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
